pattern: AdaRand
main: main/train.py
batchsize: 64
batchsize_noise: 64
epoch: 200
snapshot_interval: 1
experiment_iterations: 3
log_interval: 1
train_val_split_ratio: 0.9
log_metrics: ["loss_pseudo", "feat_norm", "grad_norm", "feat_entropy"]

models:
  pattern: ViT-B-16
  classifier:
    func: model/vit.py
    name: ViT_B_16_Feat
    args:
      num_classes: 196
      pretrained: True
      finetune: True
  generator:
    func: model/noise_generator.py
    name: MultiClassNoiseGenerator  
    args:
      ema_decay: 0.999
      num_classes: 196
      feat_dim: 768
      precomputed_stats: stats/conditional/cars_vit-b-16.npz

dataset:
  dataset_func: data/generic.py
  dataset_name: StanfordCars
  args:
    root: data/StanfordCars
    test: False
    size: 224

optimizer_c:
  algorithm: AdamW
  lr_milestone: cosine
  warmup: 30
  args:
    lr: 3.0e-5
    weight_decay: 0.1

optimizer_g:
  algorithm: Adam
  lr_milestone: cosine
  args:
    lr: 1.0e-2

updater:
  func: updater/adarand.py
  name: MultiClassUpdater
  args:
    lambda_reg: 1.0
    ema_generator: True
    num_classes: 196
    alpha: 0.5
    feat_dim: 768
